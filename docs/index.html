<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Melika Ayoughi</title>

  <meta name="author" content="Melika Ayoughi">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <link rel="stylesheet" type="text/css" href="./stylesheet.css">
	<link rel="icon" href="./images/uva_logo.png">
</head>

<body>
<!--<style>-->
<!--body {-->
<!--  background-color: coral;-->
<!--}-->
<!--</style>-->

  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Melika Ayoughi</name>
              </p>
              <p style="text-align:center">
                <a href="mailto:m.ayoughi@uva.nl">Email</a> &nbsp/&nbsp
                <a href="./data/Melika_CV.pdf">CV</a> &nbsp/&nbsp
                <a href="https://www.linkedin.com/in/melika-ayoughi/">LinkedIn</a> &nbsp/&nbsp
<!--                <a href="https://scholar.google.com/">Google Scholar</a> &nbsp/&nbsp-->
                <a href="https://twitter.com/melikaayoughi">Twitter</a> &nbsp/&nbsp
                <a href="https://github.com/Melika-Ayoughi/">Github</a>

              </p>

              <p>I am a PhD student at the <a href="https://www.uva.nl/en">University of Amsterdam</a>, where I work on extracting knowledge graphs from videos. I'm supervised jointly by <a href="https://staff.fnwi.uva.nl/p.s.m.mettes/">Pascal Mettes</a>  from <a href="https://ivi.fnwi.uva.nl/vislab/">VIS Lab</a> and <a href="http://pgroth.com/">Paul Groth</a>  from <a href="https://indelab.org/">INDE Lab</a>.
              </p>
              <p>I did an Artificial Intelligence master at the University of Amsterdam. I worked on my thesis at <a href="https://www.tomtom.com/">TomTom</a> on object detection under high class imbalance. I took part in an internship at <a href="https://dexterenergy.ai/">Dexter Energy Services</a> working on <a href="data/internship_report.pdf"> weather nowcasting using satellite images</a>.</p>


            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="./images/MelikaAyoughi.png"><img style="width:100%;max-width:100%" alt="profile photo" src="./images/MelikaAyoughi.png" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research</heading>
              <p>
                I'm interested in computer vision, and specifically multimodal data such as video, audio, text and graph. I would like to work on improving high-level understanding of videos such as object-centric learning and relationship detection and easing retrieval by storing information in a knowledge graph.
<!--                <span class="highlight">highlighted</span>.-->
              </p>
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        <span class="dark">
        <tr>
            <td style="padding:2.5%;width:25%;vertical-align:middle;min-width:120px">
              <img src="./images/method.jpg" alt="project image" style="width:auto; height:auto; max-width:100%;">
            </td>
            <td style="padding:2.5%;width:75%;vertical-align:middle">
              <h3>Self-Contained Entity Discovery from Captioned Videos</h3>
              <br>
              <strong>Melika Ayoughi</strong> , Pascal Mettes, Paul Groth
              <br>
              <em>under review of TOMM</em>, 2022
              <br>
              <a href="https://arxiv.org/abs/2208.06662">arxiv</a> /
              <a href="https://github.com/Melika-Ayoughi/Self-Contained-Video-Entity-Discovery">code</a> /
              <a href="./data/.pdf">slides</a> /

              <p></p>
              <p>This paper introduces the task of visual named entity discovery in videos without the need for task-specific supervision or task-specific external knowledge sources. Assigning specific names to entities (e.g. faces, scenes, or objects) in video frames is a long-standing challenge. Commonly, this problem is addressed as a supervised learning objective by manually annotating faces with entity labels. To bypass the annotation burden of this setup, several works have investigated the problem by utilizing external knowledge sources such as movie databases. While effective, such approaches do not work when task-specific knowledge sources are not provided and can only be applied to movies and TV series. In this work, we take the problem a step further and propose to discover entities in videos from videos and corresponding captions or subtitles. We introduce a three-stage method where we (i) create bipartite entity-name graphs from frame-caption pairs, (ii) find visual entity agreements, and (iii) refine the entity assignment through entity-level prototype construction. To tackle this new problem, we outline two new benchmarks \textsc{SC-Friends}  and \textsc{SC-BBT} based on the Friends and Big Bang Theory TV series. Experiments on the benchmarks demonstrate the ability of our approach to discover which named entity belongs to which face or scene, with an accuracy close to a supervised oracle, just from the multimodal information present in videos. Additionally, our qualitative examples show the potential challenges of self-contained discovery of any visual entity for future work.</p>

            </td>
          </tr>
        </span>
        </tbody></table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Extra Curricular</heading>
            </td>
          </tr>
        <tr>
            <td><strong>October 2020-Now: </strong>One of the organizers of the <a href="https://uva-iai.github.io/"> inclusive AI program</a></td>

        </tr>
        </tbody></table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Recent Activity</heading>
            </td>
          </tr>
        <tr>
            <td><strong>July 2022: </strong> <a ref="https://cmp.felk.cvut.cz/summerschool2022/"> Presented our work at the vision and sports summer school </a></td>
	    <td><strong>May 2022: </strong> <a ref="https://sites.google.com/view/nccv-2022"> Presented our work at the Netherlands Conference on Computer Vision</a></td>
        </tr>
        </tbody></table>
	      
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Teaching</heading>
            </td>
          </tr>
        <tr>
            <td><strong>April 2022: </strong>Bachelor Thesis Supervision</td>
            
        </tr>
        <tr>
            <td><strong>November 2021:</strong> Teaching Assistant Applied Machine Learning at UvA</td>
        </tr>
        <tr>
            <td><strong>November 2020:</strong> Teaching Assistant Applied Machine Learning at UvA</td>
        </tr>
        <tr>
            <td><strong>September 2019:</strong> Teaching Assistant Machine Learning 1 at UvA</td
        </tr>
        </tbody></table>

      </td>
    </tr>
  </table>
</body>

</html>
